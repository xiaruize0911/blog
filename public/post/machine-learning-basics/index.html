<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Machine Learning Basics | xiaruize's Blog</title><meta name=keywords content><meta name=description content="Machine Learning Basics
This article is based on Chapter 5 of Machine Learning Yearning and introduces some basic concepts and methods of machine learning.
Supervised Learning
This article mainly discusses supervised learning algorithms.
First, let’s introduce some basic concepts:

Training Set: The dataset used to train the model, containing input data (sample, $X$) and corresponding labels ($y$).
Sample: Each data point in the training set, usually represented as a vector $x^{(i)}$, where $i$ is the sample index.
Test Set: The dataset used to evaluate model performance, containing unseen input data and corresponding labels.
Input: The input data to the model, usually represented as a vector $x \in \mathbb{R}^n$, where $n$ is the input dimension.
Output: The output result of the model, usually represented as a scalar $y$, which can be a continuous value (regression) or a discrete value (classification).
Feature: Each dimension of the input data, represented as $x_1, x_2, \ldots, x_n$.
Label: The true output value corresponding to the input data, generally represented as $y$.

The main goal of supervised learning algorithms is to learn $P(y|x)$ from a training set, obtain a model to get an approximate value $\hat{P}(y|x)$, so that for new input $x$, the corresponding output $y$ can be predicted."><meta name=author content><link rel=canonical href=https://xiaruize.org/post/machine-learning-basics/><link crossorigin=anonymous href=/assets/css/stylesheet.e1f5c4cae44599655f7ff95195ff89c8cb3adbda94f2b1581a434ab2b4d4e6cf.css integrity="sha256-4fXEyuRFmWVff/lRlf+JyMs629qU8rFYGkNKsrTU5s8=" rel="preload stylesheet" as=style><link rel=icon href=https://xiaruize.org/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://xiaruize.org/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://xiaruize.org/favicon-32x32.png><link rel=apple-touch-icon href=https://xiaruize.org/apple-touch-icon.png><link rel=mask-icon href=https://xiaruize.org/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://xiaruize.org/post/machine-learning-basics/><link rel=alternate hreflang=zh href=https://xiaruize.org/zh/post/machine-learning-basics/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:url" content="https://xiaruize.org/post/machine-learning-basics/"><meta property="og:site_name" content="xiaruize's Blog"><meta property="og:title" content="Machine Learning Basics"><meta property="og:description" content="Machine Learning Basics This article is based on Chapter 5 of Machine Learning Yearning and introduces some basic concepts and methods of machine learning.
Supervised Learning This article mainly discusses supervised learning algorithms.
First, let’s introduce some basic concepts:
Training Set: The dataset used to train the model, containing input data (sample, $X$) and corresponding labels ($y$). Sample: Each data point in the training set, usually represented as a vector $x^{(i)}$, where $i$ is the sample index. Test Set: The dataset used to evaluate model performance, containing unseen input data and corresponding labels. Input: The input data to the model, usually represented as a vector $x \in \mathbb{R}^n$, where $n$ is the input dimension. Output: The output result of the model, usually represented as a scalar $y$, which can be a continuous value (regression) or a discrete value (classification). Feature: Each dimension of the input data, represented as $x_1, x_2, \ldots, x_n$. Label: The true output value corresponding to the input data, generally represented as $y$. The main goal of supervised learning algorithms is to learn $P(y|x)$ from a training set, obtain a model to get an approximate value $\hat{P}(y|x)$, so that for new input $x$, the corresponding output $y$ can be predicted."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="post"><meta property="article:published_time" content="2025-09-22T22:50:31+00:00"><meta property="article:modified_time" content="2025-09-22T22:50:31+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Machine Learning Basics"><meta name=twitter:description content="Machine Learning Basics
This article is based on Chapter 5 of Machine Learning Yearning and introduces some basic concepts and methods of machine learning.
Supervised Learning
This article mainly discusses supervised learning algorithms.
First, let’s introduce some basic concepts:

Training Set: The dataset used to train the model, containing input data (sample, $X$) and corresponding labels ($y$).
Sample: Each data point in the training set, usually represented as a vector $x^{(i)}$, where $i$ is the sample index.
Test Set: The dataset used to evaluate model performance, containing unseen input data and corresponding labels.
Input: The input data to the model, usually represented as a vector $x \in \mathbb{R}^n$, where $n$ is the input dimension.
Output: The output result of the model, usually represented as a scalar $y$, which can be a continuous value (regression) or a discrete value (classification).
Feature: Each dimension of the input data, represented as $x_1, x_2, \ldots, x_n$.
Label: The true output value corresponding to the input data, generally represented as $y$.

The main goal of supervised learning algorithms is to learn $P(y|x)$ from a training set, obtain a model to get an approximate value $\hat{P}(y|x)$, so that for new input $x$, the corresponding output $y$ can be predicted."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://xiaruize.org/post/"},{"@type":"ListItem","position":2,"name":"Machine Learning Basics","item":"https://xiaruize.org/post/machine-learning-basics/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Machine Learning Basics","name":"Machine Learning Basics","description":"Machine Learning Basics This article is based on Chapter 5 of Machine Learning Yearning and introduces some basic concepts and methods of machine learning.\nSupervised Learning This article mainly discusses supervised learning algorithms.\nFirst, let’s introduce some basic concepts:\nTraining Set: The dataset used to train the model, containing input data (sample, $X$) and corresponding labels ($y$). Sample: Each data point in the training set, usually represented as a vector $x^{(i)}$, where $i$ is the sample index. Test Set: The dataset used to evaluate model performance, containing unseen input data and corresponding labels. Input: The input data to the model, usually represented as a vector $x \\in \\mathbb{R}^n$, where $n$ is the input dimension. Output: The output result of the model, usually represented as a scalar $y$, which can be a continuous value (regression) or a discrete value (classification). Feature: Each dimension of the input data, represented as $x_1, x_2, \\ldots, x_n$. Label: The true output value corresponding to the input data, generally represented as $y$. The main goal of supervised learning algorithms is to learn $P(y|x)$ from a training set, obtain a model to get an approximate value $\\hat{P}(y|x)$, so that for new input $x$, the corresponding output $y$ can be predicted.\n","keywords":[],"articleBody":"Machine Learning Basics This article is based on Chapter 5 of Machine Learning Yearning and introduces some basic concepts and methods of machine learning.\nSupervised Learning This article mainly discusses supervised learning algorithms.\nFirst, let’s introduce some basic concepts:\nTraining Set: The dataset used to train the model, containing input data (sample, $X$) and corresponding labels ($y$). Sample: Each data point in the training set, usually represented as a vector $x^{(i)}$, where $i$ is the sample index. Test Set: The dataset used to evaluate model performance, containing unseen input data and corresponding labels. Input: The input data to the model, usually represented as a vector $x \\in \\mathbb{R}^n$, where $n$ is the input dimension. Output: The output result of the model, usually represented as a scalar $y$, which can be a continuous value (regression) or a discrete value (classification). Feature: Each dimension of the input data, represented as $x_1, x_2, \\ldots, x_n$. Label: The true output value corresponding to the input data, generally represented as $y$. The main goal of supervised learning algorithms is to learn $P(y|x)$ from a training set, obtain a model to get an approximate value $\\hat{P}(y|x)$, so that for new input $x$, the corresponding output $y$ can be predicted.\nA common way to represent datasets is to store all samples’ inputs and labels in matrices and vectors. For example, a 28*28 grayscale image can be represented as a (1,28,28) tensor, a training set with $m$ samples can be represented as a (m,1,28,28) tensor, and labels can be represented as a (m,) vector.\nExample: Linear Regression Model Linear regression is one of the simplest supervised learning algorithms. It assumes a linear relationship between input $x$ and output $y$, which can be expressed as (ignoring the intercept term for now):\n$$y = w^T x $$where $w$ is the model parameter, representing the weights of each input feature, which is the learning objective.\nAssuming we have trained the parameter $w$, for a new input $x$, we can predict the output $\\hat{y}$ by calculating $\\hat{y} = w^T x$.\nLoss Function To evaluate the performance of the model, we need to define a loss function to measure the difference between the predicted value $\\hat{y}$ and the true value $y$.\nCommon loss functions include:\nL1 loss (Mean Absolute Error, MAE):\n$$L1(y, \\hat{y}) = \\frac{1}{m} \\sum_{i=1}^{m} |y^{(i)} - \\hat{y}^{(i)}|$$Mean Squared Error (MSE):\n$$MSE(y, \\hat{y}) = \\frac{1}{m} \\sum_{i=1}^{m} (y^{(i)} - \\hat{y}^{(i)})^2$$where $m$ is the number of samples, $y^{(i)}$ and $\\hat{y}^{(i)}$ are the true and predicted values for the $i$-th sample, respectively.\nHere, we simply consider that the smaller the MSE, the better the model performance. Of course, other loss functions can be used, and different loss functions are suitable for different scenarios.\nOptimization Next, our goal is to minimize the MSE loss function and find the optimal parameter $w$.\nTo achieve this goal, we hope to find $w$ through the training set that satisfies or is as close as possible to $\\triangledown_w MSE_{train}=0$.\n$$ \\begin{align*}\n\u0026 \\triangledown_w MSE_{train} = 0\\\n\\Rightarrow \u0026 \\frac{1}{m} \\triangledown_w ||X_{train} \\cdot w-y_{train}||^2_2 = 0\\\n\\Rightarrow \u0026 \\triangledown_w (X_{train} \\cdot w-y_{train})^T (X_{train} \\cdot w-y_{train}) =0\\\n\\Rightarrow \u0026 2X_{train}^T (X_{train} \\cdot w-y_{train}) =0\\\n\\Rightarrow \u0026 w = (X_{train}^T X_{train})^{-1} X_{train}^T y_{train} \\end{align*} $$\nThe solution derived above is called the Normal Equation, which gives the closed-form solution to the linear regression problem.\n","wordCount":"551","inLanguage":"en","datePublished":"2025-09-22T22:50:31Z","dateModified":"2025-09-22T22:50:31Z","mainEntityOfPage":{"@type":"WebPage","@id":"https://xiaruize.org/post/machine-learning-basics/"},"publisher":{"@type":"Organization","name":"xiaruize's Blog","logo":{"@type":"ImageObject","url":"https://xiaruize.org/favicon.ico"}}}</script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js></script><script>MathJax={tex:{displayMath:[["\\[","\\]"],["$$","$$"]],inlineMath:[["\\(","\\)"],["$","$"]]},loader:{load:["ui/safe"]}}</script></head><body id="
    top"><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://xiaruize.org/ accesskey=h title="xiaruize's Blog (Alt + H)">xiaruize's Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li><li><a href=https://xiaruize.org/zh/ title=中文 aria-label=中文>Zh</a></li></ul></div></div><ul id=menu><li><a href=https://xiaruize.org/categories/ title=categories><span>categories</span></a></li><li><a href=https://xiaruize.org/tags/ title=tags><span>tags</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">Machine Learning Basics</h1><div class=post-meta><span title='2025-09-22 22:50:31 +0000 UTC'>September 22, 2025</span>&nbsp;|&nbsp;Translations:<ul class=i18n_list><li><a href=https://xiaruize.org/zh/post/machine-learning-basics/>Zh</a></li></ul></div></header><div class=post-content><h1 id=machine-learning-basics>Machine Learning Basics<a hidden class=anchor aria-hidden=true href=#machine-learning-basics>#</a></h1><p>This article is based on Chapter 5 of <a href=https://www.deeplearning.ai/machine-learning-yearning/>Machine Learning Yearning</a> and introduces some basic concepts and methods of machine learning.</p><h2 id=supervised-learning>Supervised Learning<a hidden class=anchor aria-hidden=true href=#supervised-learning>#</a></h2><p>This article mainly discusses supervised learning algorithms.</p><p>First, let’s introduce some basic concepts:</p><ul><li><strong>Training Set</strong>: The dataset used to train the model, containing input data (sample, $X$) and corresponding labels ($y$).</li><li><strong>Sample</strong>: Each data point in the training set, usually represented as a vector $x^{(i)}$, where $i$ is the sample index.</li><li><strong>Test Set</strong>: The dataset used to evaluate model performance, containing unseen input data and corresponding labels.</li><li><strong>Input</strong>: The input data to the model, usually represented as a vector $x \in \mathbb{R}^n$, where $n$ is the input dimension.</li><li><strong>Output</strong>: The output result of the model, usually represented as a scalar $y$, which can be a continuous value (regression) or a discrete value (classification).</li><li><strong>Feature</strong>: Each dimension of the input data, represented as $x_1, x_2, \ldots, x_n$.</li><li><strong>Label</strong>: The true output value corresponding to the input data, generally represented as $y$.</li></ul><p>The main goal of supervised learning algorithms is to learn $P(y|x)$ from a training set, obtain a model to get an approximate value $\hat{P}(y|x)$, so that for new input $x$, the corresponding output $y$ can be predicted.</p><p>A common way to represent datasets is to store all samples’ inputs and labels in matrices and vectors. For example, a 28*28 grayscale image can be represented as a (1,28,28) tensor, a training set with $m$ samples can be represented as a (m,1,28,28) tensor, and labels can be represented as a (m,) vector.</p><h2 id=example-linear-regression>Example: Linear Regression<a hidden class=anchor aria-hidden=true href=#example-linear-regression>#</a></h2><h3 id=model>Model<a hidden class=anchor aria-hidden=true href=#model>#</a></h3><p>Linear regression is one of the simplest supervised learning algorithms. It assumes a linear relationship between input $x$ and output $y$, which can be expressed as (ignoring the intercept term for now):</p>$$y = w^T x $$<p>where $w$ is the model parameter, representing the weights of each input feature, which is the learning objective.</p><p>Assuming we have trained the parameter $w$, for a new input $x$, we can predict the output $\hat{y}$ by calculating $\hat{y} = w^T x$.</p><h3 id=loss-function>Loss Function<a hidden class=anchor aria-hidden=true href=#loss-function>#</a></h3><p>To evaluate the performance of the model, we need to define a loss function to measure the difference between the predicted value $\hat{y}$ and the true value $y$.</p><p>Common loss functions include:</p><p>L1 loss (Mean Absolute Error, MAE):</p>$$L1(y, \hat{y}) = \frac{1}{m} \sum_{i=1}^{m} |y^{(i)} - \hat{y}^{(i)}|$$<p>Mean Squared Error (MSE):</p>$$MSE(y, \hat{y}) = \frac{1}{m} \sum_{i=1}^{m} (y^{(i)} - \hat{y}^{(i)})^2$$<p>where $m$ is the number of samples, $y^{(i)}$ and $\hat{y}^{(i)}$ are the true and predicted values for the $i$-th sample, respectively.</p><p>Here, we simply consider that the smaller the MSE, the better the model performance. Of course, other loss functions can be used, and different loss functions are suitable for different scenarios.</p><h3 id=optimization>Optimization<a hidden class=anchor aria-hidden=true href=#optimization>#</a></h3><p>Next, our goal is to minimize the MSE loss function and find the optimal parameter $w$.</p><p>To achieve this goal, we hope to find $w$ through the training set that satisfies or is as close as possible to $\triangledown_w MSE_{train}=0$.</p><p>$$
\begin{align*}</p><p>& \triangledown_w MSE_{train} = 0\</p><p>\Rightarrow & \frac{1}{m} \triangledown_w ||X_{train} \cdot w-y_{train}||^2_2 = 0\</p><p>\Rightarrow & \triangledown_w (X_{train} \cdot w-y_{train})^T (X_{train} \cdot w-y_{train}) =0\</p><p>\Rightarrow & 2X_{train}^T (X_{train} \cdot w-y_{train}) =0\</p><p>\Rightarrow & w = (X_{train}^T X_{train})^{-1} X_{train}^T y_{train}
\end{align*}
$$</p><p>The solution derived above is called the Normal Equation, which gives the closed-form solution to the linear regression problem.</p></div><footer class=post-footer><ul class=post-tags></ul></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://xiaruize.org/>xiaruize's Blog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>