<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Gradient Descent | xiaruize's Blog</title><meta name=keywords content><meta name=description content="Gradient Descent
Gradient Descent is an iterative algorithm used to optimize objective functions, widely applied in machine learning and deep learning to train models by minimizing loss functions. It is recommended to first read the Machine Learning Basics article for background understanding.
Objective Function
Objective Function: Sometimes also called criterion, cost function, or loss function, is the function we aim to minimize, usually denoted as $J(\theta)$, where $\theta$ is the model parameter. For example, Mean Squared Error (MSE) used in linear regression is a common objective function."><meta name=author content><link rel=canonical href=https://xiaruize.org/post/gradient-descent/><link crossorigin=anonymous href=/assets/css/stylesheet.e1f5c4cae44599655f7ff95195ff89c8cb3adbda94f2b1581a434ab2b4d4e6cf.css integrity="sha256-4fXEyuRFmWVff/lRlf+JyMs629qU8rFYGkNKsrTU5s8=" rel="preload stylesheet" as=style><link rel=icon href=https://xiaruize.org/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://xiaruize.org/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://xiaruize.org/favicon-32x32.png><link rel=apple-touch-icon href=https://xiaruize.org/apple-touch-icon.png><link rel=mask-icon href=https://xiaruize.org/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://xiaruize.org/post/gradient-descent/><link rel=alternate hreflang=zh href=https://xiaruize.org/zh/post/gradient-descent/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:url" content="https://xiaruize.org/post/gradient-descent/"><meta property="og:site_name" content="xiaruize's Blog"><meta property="og:title" content="Gradient Descent"><meta property="og:description" content="Gradient Descent Gradient Descent is an iterative algorithm used to optimize objective functions, widely applied in machine learning and deep learning to train models by minimizing loss functions. It is recommended to first read the Machine Learning Basics article for background understanding.
Objective Function Objective Function: Sometimes also called criterion, cost function, or loss function, is the function we aim to minimize, usually denoted as $J(\theta)$, where $\theta$ is the model parameter. For example, Mean Squared Error (MSE) used in linear regression is a common objective function."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="post"><meta property="article:published_time" content="2025-09-25T21:26:00+08:00"><meta property="article:modified_time" content="2025-09-25T21:26:00+08:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Gradient Descent"><meta name=twitter:description content="Gradient Descent
Gradient Descent is an iterative algorithm used to optimize objective functions, widely applied in machine learning and deep learning to train models by minimizing loss functions. It is recommended to first read the Machine Learning Basics article for background understanding.
Objective Function
Objective Function: Sometimes also called criterion, cost function, or loss function, is the function we aim to minimize, usually denoted as $J(\theta)$, where $\theta$ is the model parameter. For example, Mean Squared Error (MSE) used in linear regression is a common objective function."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://xiaruize.org/post/"},{"@type":"ListItem","position":2,"name":"Gradient Descent","item":"https://xiaruize.org/post/gradient-descent/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Gradient Descent","name":"Gradient Descent","description":"Gradient Descent Gradient Descent is an iterative algorithm used to optimize objective functions, widely applied in machine learning and deep learning to train models by minimizing loss functions. It is recommended to first read the Machine Learning Basics article for background understanding.\nObjective Function Objective Function: Sometimes also called criterion, cost function, or loss function, is the function we aim to minimize, usually denoted as $J(\\theta)$, where $\\theta$ is the model parameter. For example, Mean Squared Error (MSE) used in linear regression is a common objective function.\n","keywords":[],"articleBody":"Gradient Descent Gradient Descent is an iterative algorithm used to optimize objective functions, widely applied in machine learning and deep learning to train models by minimizing loss functions. It is recommended to first read the Machine Learning Basics article for background understanding.\nObjective Function Objective Function: Sometimes also called criterion, cost function, or loss function, is the function we aim to minimize, usually denoted as $J(\\theta)$, where $\\theta$ is the model parameter. For example, Mean Squared Error (MSE) used in linear regression is a common objective function.\nGenerally, we define $x^* = \\arg\\min_{x} J(x)$.\nDerivative Suppose we need to optimize the function $y = f(x)$, its derivative $f'(x)$ represents the rate of change at point $x$, or the slope of the tangent at that point.\nUsing the definition of the derivative, we see it indicates the trend of change at that point, helping us easily determine the direction of decrease.\nTake a small positive number $\\epsilon$, if $f'(x) \u003e 0$, then $f(x - \\epsilon) \u003c f(x)$; otherwise, $f(x + \\epsilon) \u003c f(x)$. That is:\n$$ f(x -\\epsilon\\cdot \\text{sign}(f'(x))) \u003c f(x) $$Therefore, the negative direction of the derivative is the direction of fastest decrease.\nGradient Now, let’s extend the above process to multi-dimensional space. Suppose we have a multivariate function $f: \\mathbb{R}^n \\to \\mathbb{R}$, with input as an $n$-dimensional vector $x = [x_1, x_2, \\ldots, x_n]^T$ and output as a scalar $y = f(x)$. We want to find $x$ that minimizes $f(x)$.\nIn multi-dimensional space, the concept of derivative generalizes to the gradient. The gradient is a vector containing the partial derivatives with respect to each variable, denoted as: $$ \\nabla f(x) = \\left[ \\frac{\\partial f}{\\partial x_1}, \\frac{\\partial f}{\\partial x_2}, \\ldots, \\frac{\\partial f}{\\partial x_n} \\right]^T $$Each component $\\frac{\\partial f}{\\partial x_i}$ represents the rate of change of $f$ with respect to $x_i$. The gradient vector points in the direction of the fastest increase at point $x$.\nAccording to the conclusion from the derivative section, we might think to update along the direction of the partial derivatives. In fact, for a small positive $\\epsilon$, the direction of fastest decrease for $f(x)$ is $-\\nabla f(x)$, so: $$ f(x - \\epsilon \\cdot \\nabla f(x)) \u003c f(x) $$Gradient Descent Algorithm Based on the above, we can design an iterative algorithm to find the minimum of a function: at each step, move a small step in the negative direction of the derivative, gradually approaching the minimum.\nAccording to the properties of derivatives, points where $f'(x)=0$ are not necessarily minima. In practice, we rarely end up at saddle points due to floating-point errors. However, the minima we find may not be global minima, but rather local minima, which is usually acceptable since finding the global minimum is often infeasible and local minima are good enough.\nFor example, in the following figure, it is difficult to stop exactly at point P2 due to floating-point errors, but we are likely to stop at point P1, which, although not the global minimum, is usually sufficient.\nExtending to multi-dimensional space, the gradient descent algorithm can be designed as follows:\nInitialize parameter $x$, either randomly or using a heuristic. Compute the gradient $\\nabla f(x)$. Update parameter: $x = x - \\alpha \\cdot \\nabla f(x)$, where $\\alpha$ is the learning rate, controlling the step size. Repeat steps 2 and 3 until a stopping condition is met (e.g., gradient is small enough or maximum iterations reached). Learning Rate The learning rate $\\alpha$ is an important hyperparameter in gradient descent, determining the step size for each update. Choosing an appropriate learning rate significantly affects convergence speed and final results.\nIf the learning rate is too large, updates may overshoot the optimal solution or even cause divergence. If the learning rate is too small, convergence will be very slow, requiring many iterations and increasing computational cost. Usually, the learning rate is tuned experimentally, and techniques like learning rate decay can be used to adjust it dynamically for better convergence. These techniques are not discussed here. ","wordCount":"658","inLanguage":"en","datePublished":"2025-09-25T21:26:00+08:00","dateModified":"2025-09-25T21:26:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://xiaruize.org/post/gradient-descent/"},"publisher":{"@type":"Organization","name":"xiaruize's Blog","logo":{"@type":"ImageObject","url":"https://xiaruize.org/favicon.ico"}}}</script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.21/dist/katex.min.css integrity=sha384-zh0CIslj+VczCZtlzBcjt5ppRcsAmDnRem7ESsYwWwg3m/OaJ2l4x7YBZl9Kxxib crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.21/dist/katex.min.js integrity=sha384-Rma6DA2IPUwhNxmrB/7S3Tno0YY7sFu9WSYMCuulLhIqYSGZ2gKCJWIqhBWqMQfh crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.21/dist/contrib/auto-render.min.js integrity=sha384-hCXGrW6PitJEwbkoStFjeJxv+fSOOQKOPbJxSfM6G5sWZjAyWhXiTIIAmQqnlLlh crossorigin=anonymous onload=renderMathInElement(document.body)></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"\\[",right:"\\]",display:!0},{left:"$$",right:"$$",display:!0},{left:"\\(",right:"\\)",display:!1},{left:"$",right:"$",display:!1}],throwOnError:!0})})</script></head><body id="
    top"><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://xiaruize.org/ accesskey=h title="xiaruize's Blog (Alt + H)">xiaruize's Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li><li><a href=https://xiaruize.org/zh/ title=中文 aria-label=中文>Zh</a></li></ul></div></div><ul id=menu><li><a href=https://xiaruize.org/categories/ title=categories><span>categories</span></a></li><li><a href=https://xiaruize.org/tags/ title=tags><span>tags</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">Gradient Descent</h1><div class=post-meta><span title='2025-09-25 21:26:00 +0800 CST'>September 25, 2025</span>&nbsp;|&nbsp;Translations:<ul class=i18n_list><li><a href=https://xiaruize.org/zh/post/gradient-descent/>Zh</a></li></ul></div></header><div class=post-content><h1 id=gradient-descent>Gradient Descent<a hidden class=anchor aria-hidden=true href=#gradient-descent>#</a></h1><p>Gradient Descent is an iterative algorithm used to optimize objective functions, widely applied in machine learning and deep learning to train models by minimizing loss functions. It is recommended to first read the <a href=/machine-learning-basics>Machine Learning Basics</a> article for background understanding.</p><h2 id=objective-function>Objective Function<a hidden class=anchor aria-hidden=true href=#objective-function>#</a></h2><p><strong>Objective Function</strong>: Sometimes also called criterion, cost function, or loss function, is the function we aim to minimize, usually denoted as $J(\theta)$, where $\theta$ is the model parameter. For example, Mean Squared Error (MSE) used in linear regression is a common objective function.</p><p>Generally, we define $x^* = \arg\min_{x} J(x)$.</p><h2 id=derivative>Derivative<a hidden class=anchor aria-hidden=true href=#derivative>#</a></h2><p>Suppose we need to optimize the function $y = f(x)$, its derivative $f'(x)$ represents the rate of change at point $x$, or the slope of the tangent at that point.</p><p>Using the definition of the derivative, we see it indicates the trend of change at that point, helping us easily determine the direction of decrease.</p><p>Take a small positive number $\epsilon$, if $f'(x) > 0$, then $f(x - \epsilon) < f(x)$; otherwise, $f(x + \epsilon) < f(x)$. That is:</p>$$
f(x -\epsilon\cdot \text{sign}(f'(x))) < f(x)
$$<p>Therefore, the negative direction of the derivative is the direction of fastest decrease.</p><h2 id=gradient>Gradient<a hidden class=anchor aria-hidden=true href=#gradient>#</a></h2><p>Now, let&rsquo;s extend the above process to multi-dimensional space. Suppose we have a multivariate function $f: \mathbb{R}^n \to \mathbb{R}$, with input as an $n$-dimensional vector $x = [x_1, x_2, \ldots, x_n]^T$ and output as a scalar $y = f(x)$. We want to find $x$ that minimizes $f(x)$.</p><p>In multi-dimensional space, the concept of derivative generalizes to the gradient. The gradient is a vector containing the partial derivatives with respect to each variable, denoted as:</p>$$
\nabla f(x) = \left[ \frac{\partial f}{\partial x_1}, \frac{\partial f}{\partial x_2}, \ldots, \frac{\partial f}{\partial x_n} \right]^T
$$<p>Each component $\frac{\partial f}{\partial x_i}$ represents the rate of change of $f$ with respect to $x_i$. The gradient vector points in the direction of the fastest increase at point $x$.</p><p>According to the conclusion from the derivative section, we might think to update along the direction of the partial derivatives. In fact, for a small positive $\epsilon$, the direction of fastest decrease for $f(x)$ is $-\nabla f(x)$, so:</p>$$
f(x - \epsilon \cdot \nabla f(x)) < f(x)
$$<h2 id=gradient-descent-algorithm>Gradient Descent Algorithm<a hidden class=anchor aria-hidden=true href=#gradient-descent-algorithm>#</a></h2><p>Based on the above, we can design an iterative algorithm to find the minimum of a function: at each step, move a small step in the negative direction of the derivative, gradually approaching the minimum.</p><p>According to the properties of derivatives, points where $f'(x)=0$ are not necessarily minima. In practice, we rarely end up at saddle points due to floating-point errors. However, the minima we find may not be global minima, but rather local minima, which is usually acceptable since finding the global minimum is often infeasible and local minima are good enough.</p><p>For example, in the following figure, it is difficult to stop exactly at point P2 due to floating-point errors, but we are likely to stop at point P1, which, although not the global minimum, is usually sufficient.</p><p><img alt="Gradient Descent Illustration" loading=lazy src=https://s2.loli.net/2025/09/25/2fh8Y9SxadZJcLe.png></p><p>Extending to multi-dimensional space, the gradient descent algorithm can be designed as follows:</p><ol><li>Initialize parameter $x$, either randomly or using a heuristic.</li><li>Compute the gradient $\nabla f(x)$.</li><li>Update parameter: $x = x - \alpha \cdot \nabla f(x)$, where $\alpha$ is the learning rate, controlling the step size.</li><li>Repeat steps 2 and 3 until a stopping condition is met (e.g., gradient is small enough or maximum iterations reached).</li></ol><h2 id=learning-rate>Learning Rate<a hidden class=anchor aria-hidden=true href=#learning-rate>#</a></h2><p>The learning rate $\alpha$ is an important hyperparameter in gradient descent, determining the step size for each update. Choosing an appropriate learning rate significantly affects convergence speed and final results.</p><ul><li>If the learning rate is too large, updates may overshoot the optimal solution or even cause divergence.</li><li>If the learning rate is too small, convergence will be very slow, requiring many iterations and increasing computational cost.
Usually, the learning rate is tuned experimentally, and techniques like learning rate decay can be used to adjust it dynamically for better convergence. These techniques are not discussed here.</li></ul></div><footer class=post-footer><ul class=post-tags></ul></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://xiaruize.org/>xiaruize's Blog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>