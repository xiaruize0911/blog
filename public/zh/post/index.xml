<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Posts on xiaruize&#39;s Blog</title>
    <link>https://xiaruize.org/zh/post/</link>
    <description>Recent content in Posts on xiaruize&#39;s Blog</description>
    <generator>Hugo -- 0.150.0</generator>
    <language>zh</language>
    <lastBuildDate>Mon, 22 Sep 2025 22:50:31 +0000</lastBuildDate>
    <atom:link href="https://xiaruize.org/zh/post/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>machine-learning-basics</title>
      <link>https://xiaruize.org/zh/post/machine-learning-basics/</link>
      <pubDate>Mon, 22 Sep 2025 22:50:31 +0000</pubDate>
      <guid>https://xiaruize.org/zh/post/machine-learning-basics/</guid>
      <description>&lt;h1 id=&#34;machine-learning-basics&#34;&gt;Machine Learning Basics&lt;/h1&gt;
&lt;p&gt;这篇文章基于&lt;a href=&#34;https://www.deeplearning.ai/machine-learning-yearning/&#34;&gt;Machine Learning Yearning&lt;/a&gt;一书 Chapt5，介绍机器学习的一些基本概念和方法。&lt;/p&gt;
&lt;h2 id=&#34;supervised-learning&#34;&gt;Supervised Learning&lt;/h2&gt;
&lt;p&gt;本文主要讨论监督学习算法。&lt;/p&gt;
&lt;p&gt;首先，介绍一些基本概念：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;训练集 (Training Set)&lt;/strong&gt;：用于训练模型的数据集，包含输入数据 (sample, $X$)和对应的标签（label，$y$）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;样本 (Sample)&lt;/strong&gt;：训练集中的每一个数据点，通常表示为一个向量 $x^{(i)}$，其中 $i$ 是样本的索引。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;测试集 (Test Set)&lt;/strong&gt;：用于评估模型性能的数据集，包含不被用在训练中，未见过的输入数据和对应的标签。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;输入 (Input)&lt;/strong&gt;：模型的输入数据，通常表示为一个向量 $x \in \mathbb{R}^n$，其中 $n$ 是输入的维度。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;输出 (Output)&lt;/strong&gt;：模型的输出结果，通常表示为一个标量 $y$，可以是连续值（回归问题）或离散值（分类问题）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;特征 (Feature)&lt;/strong&gt;：输入数据的各个维度，表示为 $x_1, x_2, \ldots, x_n$。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;标签 (Label)&lt;/strong&gt;：输入数据对应的真实输出值，一般表示为 $y$。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;监督学习算法的主要目的是，从一个训练集中学习 $P(y|x)$ ，得到一个模型，来获得近似值 $\hat{P}(y|x)$，使得对于新的输入 $x$，可以预测出对应的输出 $y$。&lt;/p&gt;
&lt;p&gt;表示数据集的常用方法是将所有样本的输入和标签分别存储在矩阵和向量中，例如 28*28 的灰度图像可以表示为一个 (1,28,28) 的张量，包含 $m$ 个样本的训练集可以表示为一个 (m,1,28,28) 的张量，标签可以表示为一个 (m,) 的向量。&lt;/p&gt;
&lt;h2 id=&#34;example-linear-regression&#34;&gt;Example: Linear Regression&lt;/h2&gt;
&lt;h3 id=&#34;model&#34;&gt;Model&lt;/h3&gt;
&lt;p&gt;线性回归是最简单的监督学习算法之一，假设输入 $x$ 和输出 $y$ 之间存在线性关系，可以表示为(这里先不考虑截距项)：&lt;/p&gt;
&lt;p&gt;$$y = w^T x $$&lt;/p&gt;</description>
    </item>
    <item>
      <title>deep-feedforward-neural-networks</title>
      <link>https://xiaruize.org/zh/post/deep-feedforward-neural-networks/</link>
      <pubDate>Mon, 22 Sep 2025 22:40:11 +0000</pubDate>
      <guid>https://xiaruize.org/zh/post/deep-feedforward-neural-networks/</guid>
      <description>&lt;h1 id=&#34;deep-feedforward-neural-networks&#34;&gt;Deep Feedforward Neural Networks&lt;/h1&gt;
&lt;p&gt;本文是对&lt;a href=&#34;http://www.deeplearningbook.org/&#34;&gt;Deep Learning&lt;/a&gt;一书中第6章内容的学习笔记。&lt;/p&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;深度前馈网络 (Deep Feedforward Networks)，也称为多层感知机 (Multilayer Perceptrons, MLPs)，是最经典的神经网络模型。&lt;/p&gt;
&lt;p&gt;从图论角度出发，深度前馈网络是一个有向无环图 (Directed Acyclic Graph, DAG)，其中每个节点表示一个neuron（神经元），每条边表示一个连接权重 (weight)。节点之间的连接是有方向的，信息只能沿着边的方向流动。因此，深度前馈网络没有循环 (cycles) 或反馈 (feedback) 连接。&lt;/p&gt;
&lt;p&gt;这里简单给出几个概念：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;神经元 (Neuron)&lt;/strong&gt;：神经网络中的基本计算单元，接收输入并生成输出。这里可以将每个Neuron看作一个函数，接收输入向量并输出一个标量。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;层 (Layer)&lt;/strong&gt;：神经网络中的一组神经元，通常按功能划分为输入层、隐藏层和输出层。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;输入层 (Input Layer)&lt;/strong&gt;：网络的第一层，接收外部输入数据。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;隐藏层 (Hidden Layers)&lt;/strong&gt;：位于输入层和输出层之间的中间层。隐藏层的数量和每层的神经元数量是网络设计的重要参数。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;输出层 (Output Layer)&lt;/strong&gt;：网络的最后一层，生成最终的输出结果。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;权重 (Weights)&lt;/strong&gt;：神经元的参数，决定了输入数据对输出的影响程度。权重是通过训练过程学习得到的。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;偏置 (Biases)&lt;/strong&gt;：神经元的另一个参数，允许模型更灵活地拟合数据。偏置也是通过训练过程学习得到的。&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    <item>
      <title>Deep Learning 学习小记</title>
      <link>https://xiaruize.org/zh/post/deep-learning-study-notes/</link>
      <pubDate>Mon, 22 Sep 2025 22:03:47 +0000</pubDate>
      <guid>https://xiaruize.org/zh/post/deep-learning-study-notes/</guid>
      <description>&lt;h1 id=&#34;deep-learning-学习小记&#34;&gt;Deep Learning 学习小记&lt;/h1&gt;
&lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;
&lt;p&gt;本文是一些关于DL方向的学习笔记和项目记录的汇总目录。&lt;/p&gt;
&lt;p&gt;感谢读者的阅读，如果有任何问题欢迎留言或者联系我 &lt;a href=&#34;mailto:xiaruize0911@gmail.com&#34;&gt;email&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;谢谢&lt;/p&gt;
&lt;h2 id=&#34;目录&#34;&gt;目录&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://xiaruize.org/machine-learning-basics/&#34;&gt;Machine Learning Basics&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://xiaruize.org/deep-feedforward-neural-networks/&#34;&gt;Deep Feedforward Neural Networks&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    <item>
      <title>Hello World</title>
      <link>https://xiaruize.org/zh/post/hello-world/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://xiaruize.org/zh/post/hello-world/</guid>
      <description>&lt;h3 id=&#34;hi-there-&#34;&gt;Hi there! 👋&lt;/h3&gt;
&lt;p&gt;I’m &lt;strong&gt;Ruize Xia&lt;/strong&gt; (xiaruize0911), a student at &lt;strong&gt;Nanjing Foreign Language School&lt;/strong&gt; in &lt;strong&gt;Nanjing, Jiangsu, China&lt;/strong&gt;. I am passionate about learning and exploring new technologies and ideas.&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;-location&#34;&gt;🌍 Location&lt;/h3&gt;
&lt;p&gt;📍 Nanjing, Jiangsu, China&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;-contact-me&#34;&gt;📫 Contact Me&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Email&lt;/strong&gt;: &lt;a href=&#34;mailto:xiaruize0911@gmail.com&#34;&gt;xiaruize0911@gmail.com&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;QQ&lt;/strong&gt;: 2188298460&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;WeChat&lt;/strong&gt;: xiaruize0911&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;Thank you for visiting! Feel free to explore my blog and connect with me. 🚀&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
